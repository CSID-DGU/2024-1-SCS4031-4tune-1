Index: .idea/sonarlint/issuestore/index.pb
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\n9\n\tREADME.md\u0012,8/e/8ec9a00bfd09b3190ac6b22251dbb1aa95a0579d\nP\n src/ai/4tune_AI/requirements.txt\u0012,2/6/26f666c05e7d5cb7b6c2a7012ddbf42ab1d4a20a
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/sonarlint/issuestore/index.pb b/.idea/sonarlint/issuestore/index.pb
--- a/.idea/sonarlint/issuestore/index.pb	(revision dc877692707894d8716e12b97fb670c3988bdcb7)
+++ b/.idea/sonarlint/issuestore/index.pb	(date 1733546908898)
@@ -2,4 +2,14 @@
 9
 	README.md,8/e/8ec9a00bfd09b3190ac6b22251dbb1aa95a0579d
 P
- src/ai/4tune_AI/requirements.txt,2/6/26f666c05e7d5cb7b6c2a7012ddbf42ab1d4a20a
\ No newline at end of file
+ src/ai/4tune_AI/requirements.txt,2/6/26f666c05e7d5cb7b6c2a7012ddbf42ab1d4a20a
+Y
+)src/ai/4tune_AI/gaze_ver2/custom_utils.py,a/7/a70493e17a32b9711265c1284ac59eb6e5671d82
+V
+&src/ai/4tune_AI/gaze_ver2/detectors.py,6/c/6cab8a4365ae784aa4f202efee07f97f341353c5
+Q
+!src/ai/4tune_AI/gaze_ver2/main.py,9/1/910cd19debf0f1bc66164aaa9e87c0ebd1344080
+V
+&src/ai/4tune_AI/gaze_ver2/constants.py,b/f/bf708a643db2ad11ba0f446c8def2b82584dd087
+Q
+!src/ai/4tune_AI/test_gaze/main.py,9/3/93f3326e910973ce417d1a3bb23124e3620193ba
\ No newline at end of file
Index: src/ai/4tune_AI/gaze_ver2/custom_utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/ai/4tune_AI/gaze_ver2/custom_utils.py b/src/ai/4tune_AI/gaze_ver2/custom_utils.py
new file mode 100644
--- /dev/null	(date 1733546536110)
+++ b/src/ai/4tune_AI/gaze_ver2/custom_utils.py	(date 1733546536110)
@@ -0,0 +1,121 @@
+import cv2
+import numpy as np
+from PIL import ImageFont, ImageDraw, Image
+import math
+
+def draw_text_korean(image, text, position, font_size=30, font_color=(0, 0, 255)):
+    # OpenCV 이미지를 PIL 이미지로 변환
+    image_pil = Image.fromarray(image)
+    draw = ImageDraw.Draw(image_pil)
+
+    # 폰트 설정 (MacOS의 경우)
+    font = ImageFont.truetype('/Library/Fonts/AppleGothic.ttf', font_size)
+    # Windows의 경우
+    # font = ImageFont.truetype('C:/Windows/Fonts/malgun.ttf', font_size)
+
+    # 텍스트 그리기
+    draw.text(position, text, font=font, fill=font_color)
+
+    # PIL 이미지를 OpenCV 이미지로 변환
+    image = np.array(image_pil)
+    return image
+
+def calculate_head_pose(landmarks, image_shape):
+    # 3D 모델 포인트 설정
+    model_points = np.array([
+        (0.0, 0.0, 0.0),             # 코 끝
+        (0.0, -330.0, -65.0),        # 턱 끝
+        (-225.0, 170.0, -135.0),     # 왼쪽 눈 좌측 끝
+        (225.0, 170.0, -135.0),      # 오른쪽 눈 우측 끝
+        (-150.0, -150.0, -125.0),    # 입 좌측 끝
+        (150.0, -150.0, -125.0)      # 입 우측 끝
+    ])
+
+    image_points = np.array([
+        (landmarks[1][0], landmarks[1][1]),    # 코 끝
+        (landmarks[152][0], landmarks[152][1]),  # 턱 끝
+        (landmarks[33][0], landmarks[33][1]),   # 왼쪽 눈 좌측 끝
+        (landmarks[263][0], landmarks[263][1]),  # 오른쪽 눈 우측 끝
+        (landmarks[61][0], landmarks[61][1]),   # 입 좌측 끝
+        (landmarks[291][0], landmarks[291][1])  # 입 우측 끝
+    ], dtype='double')
+
+    # 카메라 매트릭스 설정
+    focal_length = image_shape[1]
+    center = (image_shape[1] / 2, image_shape[0] / 2)
+    camera_matrix = np.array(
+        [[focal_length, 0, center[0]],
+         [0, focal_length, center[1]],
+         [0, 0, 1]], dtype='double')
+
+    dist_coeffs = np.zeros((4, 1))  # 왜곡 계수는 0으로 설정
+
+    # SolvePnP를 사용하여 회전 및 변환 벡터 계산
+    success, rotation_vector, translation_vector = cv2.solvePnP(
+        model_points, image_points, camera_matrix, dist_coeffs)
+
+    # 회전 벡터를 오일러 각도로 변환
+    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
+    pose_matrix = cv2.hconcat((rotation_matrix, translation_vector))
+    _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(pose_matrix)
+
+    pitch, yaw, roll = [angle[0] for angle in euler_angles]
+
+    return pitch, yaw, roll
+
+def get_landmarks(face_landmarks, image_shape):
+    h, w = image_shape[:2]
+    landmarks = {}
+    for idx, lm in enumerate(face_landmarks.landmark):
+        x, y = int(lm.x * w), int(lm.y * h)
+        landmarks[idx] = (x, y)
+    return landmarks
+
+def get_gaze_position(landmarks):
+    # 눈 중심 계산
+    left_eye = landmarks[468]
+    right_eye = landmarks[473]
+    gaze_point = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)
+    return gaze_point
+
+def calculate_eye_position(landmarks):
+    # 왼쪽 눈의 랜드마크 인덱스
+    left_eye_indices = [33, 133]
+    right_eye_indices = [362, 263]
+
+    left_eye = np.mean([landmarks[idx] for idx in left_eye_indices], axis=0).astype(int)
+    right_eye = np.mean([landmarks[idx] for idx in right_eye_indices], axis=0).astype(int)
+
+    # 두 눈의 중심 계산
+    eye_center = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)
+
+    return eye_center
+
+
+def recognize_hand_gesture(hand_landmarks):
+    # 손가락의 각 관절 랜드마크 인덱스
+    finger_tips = [4, 8, 12, 16, 20]    # 엄지, 검지, 중지, 약지, 새끼 손가락 끝
+    finger_pips = [2, 6, 10, 14, 18]    # 각 손가락의 PIP 관절
+
+    finger_states = []
+
+    for tip, pip in zip(finger_tips, finger_pips):
+        tip_y = hand_landmarks.landmark[tip].y
+        pip_y = hand_landmarks.landmark[pip].y
+
+        # 손바닥이 위를 향한다고 가정 (
+        if tip_y < pip_y:
+            finger_states.append(1)  # 손가락이 펴져 있음
+        else:
+            finger_states.append(0)  # 손가락이 접혀 있음
+
+    # 모든 손가락이 펴져 있는 경우 'palm'
+    if sum(finger_states) == 5:
+        return 'palm'
+
+    # 모든 손가락이 접혀 있는 경우 'fist'
+    if sum(finger_states) == 0:
+        return 'fist'
+
+    # 그 외의 경우 'other'
+    return 'other'
Index: src/ai/4tune_AI/gaze_ver2/constants.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/ai/4tune_AI/gaze_ver2/constants.py b/src/ai/4tune_AI/gaze_ver2/constants.py
new file mode 100644
--- /dev/null	(date 1733546536110)
+++ b/src/ai/4tune_AI/gaze_ver2/constants.py	(date 1733546536110)
@@ -0,0 +1,45 @@
+# 부정행위 감지 임계값 설정
+
+# 1. 주변 응시 감지
+LOOK_AROUND_THRESHOLD = 5         # 주변을 5초 이상 응시
+
+# 2. 동일 위치 반복 응시 감지
+REPEATED_GAZE_DURATION = 3        # 동일 위치에서 3초 이상 응시
+REPEATED_GAZE_COUNT = 5           # 30초 이내에 5번
+REPEATED_GAZE_WINDOW = 30         # 30초의 시간 창
+
+# 3. 부정행위 물체 감지
+CHEATING_OBJECTS = ['cell phone', 'paper']  # 스마트폰, 작은 종이 (시험지는 제외)
+
+# 4. 장기 화면 이탈 감지
+FACE_ABSENCE_THRESHOLD = 5        # 화면에서 5초 이상 이탈
+
+# 5. 반복 화면 이탈 감지
+FACE_ABSENCE_DURATION = 3         # 이탈 지속 시간
+FACE_ABSENCE_COUNT_THRESHOLD = 5  # 30초 이내에 5번 이탈
+FACE_ABSENCE_WINDOW = 30          # 30초의 시간 창
+
+# 8. 특정 손동작 반복 감지
+HAND_GESTURE_THRESHOLD = 2        # 손동작이 2초 이상 지속될 때 부정행위로 간주
+HAND_GESTURE_EXCLUDE = ['fist', 'palm', 'holding_pencil']  # 제외할 손동작 목록
+
+# 9. 고개 돌림 유지 감지
+HEAD_TURN_THRESHOLD = 15          # 고개 돌림 각도 임계값 (Yaw)
+HEAD_TURN_DURATION = 5            # 고개 돌리고 5초 이상 유지
+
+# 10. 고개 돌림 반복 감지
+HEAD_TURN_REPEAT_DURATION = 3     # 고개 돌림 반복 시 3초 이상
+HEAD_TURN_COUNT_THRESHOLD = 5     # 30초 이내에 5번 행함
+HEAD_TURN_WINDOW = 30             # 30초의 시간 창
+
+# 기타 상수
+PITCH_DOWN_THRESHOLD = 30        # 사용자가 아래를 보고 있다고 판단할 Pitch 각도 임계값
+YAW_FORWARD_THRESHOLD = 20        # 정면을 보고 있다고 판단할 Yaw 각도 임계값
+GRID_ROWS = 3                     # 시선 추적 격자 행 수
+GRID_COLS = 3                     # 시선 추적 격자 열 수
+
+# 눈동자 움직임 감지 임계값
+EYE_MOVEMENT_THRESHOLD = 50       # 눈동자가 좌우로 움직였을 때 임계값 (픽셀 단위)
+
+# 부정행위 메시지 표시 시간
+CHEATING_MESSAGE_DURATION = 3     # 부정행위 메시지를 화면에 표시할 시간 (초)
\ No newline at end of file
Index: .idea/sonarlint/securityhotspotstore/index.pb
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\n9\n\tREADME.md\u0012,8/e/8ec9a00bfd09b3190ac6b22251dbb1aa95a0579d\nP\n src/ai/4tune_AI/requirements.txt\u0012,2/6/26f666c05e7d5cb7b6c2a7012ddbf42ab1d4a20a
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/sonarlint/securityhotspotstore/index.pb b/.idea/sonarlint/securityhotspotstore/index.pb
--- a/.idea/sonarlint/securityhotspotstore/index.pb	(revision dc877692707894d8716e12b97fb670c3988bdcb7)
+++ b/.idea/sonarlint/securityhotspotstore/index.pb	(date 1733546908899)
@@ -2,4 +2,14 @@
 9
 	README.md,8/e/8ec9a00bfd09b3190ac6b22251dbb1aa95a0579d
 P
- src/ai/4tune_AI/requirements.txt,2/6/26f666c05e7d5cb7b6c2a7012ddbf42ab1d4a20a
\ No newline at end of file
+ src/ai/4tune_AI/requirements.txt,2/6/26f666c05e7d5cb7b6c2a7012ddbf42ab1d4a20a
+Y
+)src/ai/4tune_AI/gaze_ver2/custom_utils.py,a/7/a70493e17a32b9711265c1284ac59eb6e5671d82
+V
+&src/ai/4tune_AI/gaze_ver2/detectors.py,6/c/6cab8a4365ae784aa4f202efee07f97f341353c5
+Q
+!src/ai/4tune_AI/gaze_ver2/main.py,9/1/910cd19debf0f1bc66164aaa9e87c0ebd1344080
+V
+&src/ai/4tune_AI/gaze_ver2/constants.py,b/f/bf708a643db2ad11ba0f446c8def2b82584dd087
+Q
+!src/ai/4tune_AI/test_gaze/main.py,9/3/93f3326e910973ce417d1a3bb23124e3620193ba
\ No newline at end of file
Index: src/ai/4tune_AI/test_gaze/fram.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/ai/4tune_AI/test_gaze/fram.py b/src/ai/4tune_AI/test_gaze/fram.py
new file mode 100644
--- /dev/null	(date 1733546536112)
+++ b/src/ai/4tune_AI/test_gaze/fram.py	(date 1733546536112)
@@ -0,0 +1,380 @@
+# main.py
+
+import cv2
+import mediapipe as mp
+import time
+import numpy as np
+from PIL import Image, ImageDraw, ImageFont
+import math
+
+# =========================
+# 1. 상수 및 설정값
+# =========================
+
+# 부정행위로 간주할 지속 시간 (초)
+CHEATING_THRESHOLD = 3  # 3초 이상 지속 시 부정행위로 판단
+
+# 머리 회전 각도 기준치
+HEAD_TURN_THRESHOLD = 20  # 각도 절댓값이 20도 이상이면 고개를 돌린 것으로 판단
+
+# 눈동자 각도 기준치
+EYE_TURN_THRESHOLD = 20  # 정면 기준 좌우 20도 이상이면 눈동자를 돌린 것으로 판단
+
+# 프레임 샘플링 간격 설정
+FRAME_SAMPLING_INTERVAL = 5  # 원하는 샘플링 간격으로 설정 (예: 5)
+
+# 한글 폰트 경로 설정
+# font = ImageFont.truetype('C:/Windows/Fonts/malgun.ttf', font_size)  # Windows의 경우
+font_path = '/Library/Fonts/AppleGothic.ttf'  # MacOS의 경우
+
+# =========================
+# 2. 유틸리티 함수
+# =========================
+
+def draw_text_korean(image, text, position, font_size=30, font_color=(0, 0, 255)):
+    # OpenCV 이미지를 PIL 이미지로 변환
+    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
+    draw = ImageDraw.Draw(image_pil)
+
+    # 폰트 설정
+    font = ImageFont.truetype(font_path, font_size)
+
+    # 텍스트 그리기
+    draw.text(position, text, font=font, fill=font_color)
+
+    # PIL 이미지를 OpenCV 이미지로 변환
+    image = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)
+    return image
+
+def calculate_head_pose(landmarks, image_shape):
+    # 3D 모델 포인트 설정
+    model_points = np.array([
+        (0.0, 0.0, 0.0),             # 코 끝: 1번 랜드마크
+        (0.0, -330.0, -65.0),        # 턱 끝: 152번 랜드마크
+        (-225.0, 170.0, -135.0),     # 왼쪽 눈 좌측 끝: 33번 랜드마크
+        (225.0, 170.0, -135.0),      # 오른쪽 눈 우측 끝: 263번 랜드마크
+        (-150.0, -150.0, -125.0),    # 입 좌측 끝: 78번 랜드마크
+        (150.0, -150.0, -125.0)      # 입 우측 끝: 308번 랜드마크
+    ])
+
+    image_points = np.array([
+        (landmarks.landmark[1].x * image_shape[1], landmarks.landmark[1].y * image_shape[0]),    # 코 끝
+        (landmarks.landmark[152].x * image_shape[1], landmarks.landmark[152].y * image_shape[0]),  # 턱 끝
+        (landmarks.landmark[33].x * image_shape[1], landmarks.landmark[33].y * image_shape[0]),   # 왼쪽 눈 좌측 끝
+        (landmarks.landmark[263].x * image_shape[1], landmarks.landmark[263].y * image_shape[0]),  # 오른쪽 눈 우측 끝
+        (landmarks.landmark[78].x * image_shape[1], landmarks.landmark[78].y * image_shape[0]),   # 입 좌측 끝
+        (landmarks.landmark[308].x * image_shape[1], landmarks.landmark[308].y * image_shape[0])  # 입 우측 끝
+    ], dtype='double')
+
+    # 카메라 매트릭스 설정
+    focal_length = image_shape[1]
+    center = (image_shape[1] / 2, image_shape[0] / 2)
+    camera_matrix = np.array(
+        [[focal_length, 0, center[0]],
+         [0, focal_length, center[1]],
+         [0, 0, 1]], dtype='double')
+
+    dist_coeffs = np.zeros((4, 1))  # 왜곡 계수는 0으로 설정
+
+    # SolvePnP를 사용하여 회전 및 변환 벡터 계산
+    success, rotation_vector, translation_vector = cv2.solvePnP(
+        model_points, image_points, camera_matrix, dist_coeffs)
+
+    # 회전 벡터를 오일러 각도로 변환
+    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
+    pose_matrix = cv2.hconcat((rotation_matrix, translation_vector))
+    _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(pose_matrix)
+
+    pitch, yaw, roll = [angle[0] for angle in euler_angles]
+
+    return pitch, yaw, roll
+
+def calculate_eye_direction(landmarks, image_shape):
+    # 왼쪽 및 오른쪽 눈동자 중심 계산
+    h, w = image_shape[:2]
+
+    left_eye = landmarks.landmark[468]  # 왼쪽 눈동자 중심
+    right_eye = landmarks.landmark[473]  # 오른쪽 눈동자 중심
+
+    left_eye_point = np.array([left_eye.x * w, left_eye.y * h])
+    right_eye_point = np.array([right_eye.x * w, right_eye.y * h])
+
+    # 눈동자 중심의 평균 좌표 계산
+    eyes_center = (left_eye_point + right_eye_point) / 2
+
+    # 코 끝 좌표 추출
+    nose_tip = landmarks.landmark[1]
+    nose_point = np.array([nose_tip.x * w, nose_tip.y * h])
+
+    # 시선 벡터 계산
+    gaze_vector = eyes_center - nose_point
+
+    # 시선 방향 계산 (각도)
+    dx = gaze_vector[0]
+    dy = -gaze_vector[1]  # y축 반전
+
+    angle = math.degrees(math.atan2(dy, dx))
+    if angle < 0:
+        angle += 360
+
+    return angle
+
+def detect_hand_gesture(hand_landmarks):
+    # 손가락이 펴져 있는지 확인하여 특정 제스처를 인식
+    # 엄지, 검지, 중지, 약지, 소지에 대한 랜드마크 인덱스
+    finger_tips = [4, 8, 12, 16, 20]
+    finger_pip = [3, 7, 11, 15, 19]
+
+    fingers_status = []
+
+    for tip, pip in zip(finger_tips, finger_pip):
+        tip_y = hand_landmarks.landmark[tip].y
+        pip_y = hand_landmarks.landmark[pip].y
+
+        if tip_y < pip_y:
+            fingers_status.append(1)  # 손가락 펴짐
+        else:
+            fingers_status.append(0)  # 손가락 구부러짐
+
+    # 모든 손가락이 펴져 있으면 특정 제스처로 판단
+    if sum(fingers_status) == 5:
+        return True  # 부정행위 제스처 감지
+    else:
+        return False
+
+# =========================
+# 3. 부정행위 감지 함수
+# =========================
+
+def detect_face_absence(face_present, start_times, cheating_flags, cheating_counts):
+    current_time = time.time()
+    if not face_present:
+        if start_times['face'] is None:
+            start_times['face'] = current_time
+        else:
+            elapsed_time = current_time - start_times['face']
+            if elapsed_time >= CHEATING_THRESHOLD and not cheating_flags['face']:
+                cheating_flags['face'] = True
+                cheating_counts['face'] += 1
+                current_time_str = time.strftime("%Y-%m-%d %H:%M:%S")
+                print(f'부정행위 감지! 유형: 얼굴 미검출, 시간: {current_time_str}, 횟수: {cheating_counts["face"]}')
+    else:
+        start_times['face'] = None
+        cheating_flags['face'] = False
+
+def detect_head_turn(yaw, start_times, cheating_flags, cheating_counts):
+    current_time = time.time()
+    if abs(yaw) > HEAD_TURN_THRESHOLD:
+        if start_times['head'] is None:
+            start_times['head'] = current_time
+        else:
+            elapsed_time = current_time - start_times['head']
+            if elapsed_time >= CHEATING_THRESHOLD and not cheating_flags['head']:
+                cheating_flags['head'] = True
+                cheating_counts['head'] += 1
+                current_time_str = time.strftime("%Y-%m-%d %H:%M:%S")
+                print(f'부정행위 감지! 유형: 고개 돌림, 시간: {current_time_str}, 횟수: {cheating_counts["head"]}')
+    else:
+        start_times['head'] = None
+        cheating_flags['head'] = False
+
+def detect_eye_movement(eye_angle, start_times, cheating_flags, cheating_counts):
+    current_time = time.time()
+    if eye_angle < (90 - EYE_TURN_THRESHOLD) or eye_angle > (90 + EYE_TURN_THRESHOLD):
+        if start_times['eye'] is None:
+            start_times['eye'] = current_time
+        else:
+            elapsed_time = current_time - start_times['eye']
+            if elapsed_time >= CHEATING_THRESHOLD and not cheating_flags['eye']:
+                cheating_flags['eye'] = True
+                cheating_counts['eye'] += 1
+                current_time_str = time.strftime("%Y-%m-%d %H:%M:%S")
+                print(f'부정행위 감지! 유형: 눈동자 돌림, 시간: {current_time_str}, 횟수: {cheating_counts["eye"]}')
+    else:
+        start_times['eye'] = None
+        cheating_flags['eye'] = False
+
+def detect_hand_gesture_wrapper(hand_gesture_detected, hand_label, start_times, cheating_flags, cheating_counts):
+    current_time = time.time()
+    if hand_gesture_detected:
+        if start_times['hand'].get(hand_label) is None:
+            start_times['hand'][hand_label] = current_time
+        else:
+            elapsed_time = current_time - start_times['hand'][hand_label]
+            if elapsed_time >= CHEATING_THRESHOLD and not cheating_flags['hand'].get(hand_label, False):
+                cheating_flags['hand'][hand_label] = True
+                cheating_counts['hand'][hand_label] = cheating_counts['hand'].get(hand_label, 0) + 1
+                current_time_str = time.strftime("%Y-%m-%d %H:%M:%S")
+                print(f'부정행위 감지! 유형: 손동작, 손: {hand_label}, 시간: {current_time_str}, 횟수: {cheating_counts["hand"][hand_label]}')
+    else:
+        start_times['hand'][hand_label] = None
+        cheating_flags['hand'][hand_label] = False
+
+# =========================
+# 4. 메인 실행 부분
+# =========================
+
+def main():
+    # MediaPipe 초기화
+    mp_face_mesh = mp.solutions.face_mesh
+    mp_face_detection = mp.solutions.face_detection
+    mp_hands = mp.solutions.hands
+
+    face_mesh = mp_face_mesh.FaceMesh(
+        max_num_faces=1,
+        refine_landmarks=True,
+        min_detection_confidence=0.5,
+        min_tracking_confidence=0.5
+    )
+    face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)
+    hands = mp_hands.Hands(
+        max_num_hands=2,  # 두 손 인식을 위해 2로 설정
+        min_detection_confidence=0.5,
+        min_tracking_confidence=0.5
+    )
+
+    # 그리기 유틸리티
+    mp_drawing = mp.solutions.drawing_utils
+
+    # 부정행위 관련 변수 초기화
+    start_times = {'head': None, 'eye': None, 'face': None, 'hand': {}}
+    cheating_flags = {'head': False, 'eye': False, 'face': False, 'hand': {}}
+    cheating_counts = {'head': 0, 'eye': 0, 'face': 0, 'hand': {}}
+
+    frame_count = 0  # 프레임 카운터 변수 추가
+
+    # 웹캠 열기
+    cap = cv2.VideoCapture(0)
+
+    while cap.isOpened():
+        success, image = cap.read()
+        if not success:
+            print("카메라에서 프레임을 읽을 수 없습니다.")
+            break
+
+        frame_count += 1  # 프레임 카운터 증가
+
+        # 프레임 샘플링: 지정한 간격의 프레임만 처리
+        if frame_count % FRAME_SAMPLING_INTERVAL != 0:
+            continue  # 다음 프레임으로 넘어감
+
+        # 성능 향상을 위해 이미지 쓰기 권한 해제
+        image.flags.writeable = False
+        # BGR 이미지를 RGB로 변환
+        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
+
+        # 얼굴 검출
+        face_results = face_detection.process(image_rgb)
+        face_present = False if not face_results.detections else True
+
+        # 얼굴 부정행위 감지
+        detect_face_absence(face_present, start_times, cheating_flags, cheating_counts)
+
+        # 얼굴 랜드마크 추출
+        face_mesh_results = face_mesh.process(image_rgb)
+
+        # 손 랜드마크 추출
+        hands_results = hands.process(image_rgb)
+
+        # 이미지 쓰기 권한 재설정
+        image.flags.writeable = True
+        # RGB 이미지를 BGR로 변환
+        image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
+
+        if face_mesh_results.multi_face_landmarks:
+            face_landmarks = face_mesh_results.multi_face_landmarks[0]
+
+            # 머리 자세 추정
+            pitch, yaw, roll = calculate_head_pose(face_landmarks, image.shape)
+
+            # 머리 부정행위 감지
+            detect_head_turn(yaw, start_times, cheating_flags, cheating_counts)
+
+            # 눈동자 움직임 추적
+            eye_angle = calculate_eye_direction(face_landmarks, image.shape)
+
+            # 눈동자 부정행위 감지
+            detect_eye_movement(eye_angle, start_times, cheating_flags, cheating_counts)
+
+            # 얼굴 랜드마크 그리기 (디버깅용)
+            mp_drawing.draw_landmarks(
+                image, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS,
+                landmark_drawing_spec=None,
+                connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1)
+            )
+
+            # 머리 자세 정보 표시
+            text = f'Yaw(좌우): {yaw:.1f}, Pitch(상하): {pitch:.1f}, Roll(기울기): {roll:.1f}'
+            image = draw_text_korean(image, text, (30, 30), font_size=20, font_color=(255, 255, 255))
+
+        else:
+            # 얼굴 랜드마크가 검출되지 않는 경우
+            start_times['head'] = None
+            cheating_flags['head'] = False
+            start_times['eye'] = None
+            cheating_flags['eye'] = False
+
+        # 손동작 감지
+        if hands_results.multi_hand_landmarks:
+            for hand_landmarks, hand_info in zip(hands_results.multi_hand_landmarks, hands_results.multi_handedness):
+                hand_label = hand_info.classification[0].label  # 'Left' 또는 'Right'
+
+                # 부정행위 관련 변수 초기화
+                if hand_label not in start_times['hand']:
+                    start_times['hand'][hand_label] = None
+                    cheating_flags['hand'][hand_label] = False
+                    cheating_counts['hand'][hand_label] = 0
+
+                # 부정행위 제스처 감지
+                hand_gesture_detected = detect_hand_gesture(hand_landmarks)
+
+                # 손동작 부정행위 감지
+                detect_hand_gesture_wrapper(hand_gesture_detected, hand_label, start_times, cheating_flags, cheating_counts)
+
+                # 손 랜드마크 그리기 (디버깅용)
+                mp_drawing.draw_landmarks(
+                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS,
+                    mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),
+                    mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)
+                )
+        else:
+            start_times['hand'] = {}
+            cheating_flags['hand'] = {}
+
+        # 부정행위 상태 표시
+        status_text = ''
+        if cheating_flags['face']:
+            status_text += '부정행위 감지: 얼굴 미검출\n'
+        if cheating_flags['head']:
+            status_text += '부정행위 감지: 고개 돌림\n'
+        if cheating_flags['eye']:
+            status_text += '부정행위 감지: 눈동자 돌림\n'
+        for hand_label, flag in cheating_flags['hand'].items():
+            if flag:
+                status_text += f'부정행위 감지: 손동작 (손: {hand_label})\n'
+        if status_text == '':
+            status_text = '정상 상태'
+
+        # 상태 표시
+        y0, dy = 60, 30
+        for i, line in enumerate(status_text.strip().split('\n')):
+            y = y0 + i * dy
+            image = draw_text_korean(
+                image,
+                line,
+                (30, y),
+                font_size=20,
+                font_color=(0, 0, 255) if '부정행위' in line else (0, 255, 0)
+            )
+
+        # 결과 이미지 출력
+        cv2.imshow('Gaze and Motion Tracking', image)
+
+        if cv2.waitKey(5) & 0xFF == 27:  # ESC 키를 누르면 종료
+            break
+
+    cap.release()
+    cv2.destroyAllWindows()
+
+if __name__ == '__main__':
+    main()
\ No newline at end of file
Index: src/ai/4tune_AI/test_gaze/constants.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/ai/4tune_AI/test_gaze/constants.py b/src/ai/4tune_AI/test_gaze/constants.py
new file mode 100644
--- /dev/null	(date 1733546536112)
+++ b/src/ai/4tune_AI/test_gaze/constants.py	(date 1733546536112)
@@ -0,0 +1,8 @@
+# 부정행위로 간주할 지속 시간 (초)
+CHEATING_THRESHOLD = 3  # 3초 이상 지속 시 부정행위로 판단
+
+# 머리 회전 각도 기준치
+HEAD_TURN_THRESHOLD = 20  # 각도 절댓값이 20도 이상이면 고개를 돌린 것으로 판단
+
+# 눈동자 각도 기준치
+EYE_TURN_THRESHOLD = 20  # 정면 기준 좌우 20도 이상이면 눈동자를 돌린 것으로 판단
\ No newline at end of file
Index: src/ai/4tune_AI/gaze_ver2/detectors.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/ai/4tune_AI/gaze_ver2/detectors.py b/src/ai/4tune_AI/gaze_ver2/detectors.py
new file mode 100644
--- /dev/null	(date 1733546536111)
+++ b/src/ai/4tune_AI/gaze_ver2/detectors.py	(date 1733546536111)
@@ -0,0 +1,196 @@
+import time
+import cv2
+from constants import *
+from custom_utils import *
+
+def detect_look_around(pitch, yaw, start_times, cheating_flags, cheating_counts, cheating_messages):
+    current_time = time.time()
+    if pitch <= PITCH_DOWN_THRESHOLD and abs(yaw) > YAW_FORWARD_THRESHOLD:
+        if start_times['look_around'] is None:
+            start_times['look_around'] = current_time
+        else:
+            elapsed_time = current_time - start_times['look_around']
+            if elapsed_time >= LOOK_AROUND_THRESHOLD and not cheating_flags['look_around']:
+                cheating_flags['look_around'] = True
+                cheating_counts['look_around'] += 1
+                timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(current_time))
+                message = {'type': '주변 응시', 'start_time': current_time}
+                cheating_messages.append(message)
+                print(f'[{timestamp}] 유형: 주변 응시, 횟수: {cheating_counts["look_around"]}')
+    else:
+        if cheating_flags['look_around']:
+            cheating_flags['look_around'] = False
+            start_times['look_around'] = None
+
+def detect_repeated_gaze(grid_position, gaze_history, start_times, cheating_flags, cheating_counts, cheating_messages, pitch):
+    current_time = time.time()
+    if pitch <= PITCH_DOWN_THRESHOLD:
+        gaze_history.append((grid_position, current_time))
+        # 30초 이내의 기록만 유지
+        gaze_history[:] = [(pos, t) for pos, t in gaze_history if current_time - t <= REPEATED_GAZE_WINDOW]
+
+        # 특정 위치에서 3초 이상 응시한 횟수 카운트
+        position_times = {}
+        for pos, t in gaze_history:
+            if pos not in position_times:
+                position_times[pos] = [t]
+            else:
+                position_times[pos].append(t)
+
+        repeated_gaze_count = 0
+        for pos, times in position_times.items():
+            times.sort()
+            for i in range(len(times) - 1):
+                if times[i+1] - times[i] <= REPEATED_GAZE_DURATION:
+                    repeated_gaze_count += 1
+                    break  # 해당 위치에서 한 번만 카운트
+
+        if repeated_gaze_count >= REPEATED_GAZE_COUNT and not cheating_flags['repeated_gaze']:
+            cheating_flags['repeated_gaze'] = True
+            cheating_counts['repeated_gaze'] += 1
+            timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(current_time))
+            message = {'type': '동일 위치 반복 응시', 'start_time': current_time}
+            cheating_messages.append(message)
+            print(f'[{timestamp}] 유형: 동일 위치 반복 응시, 횟수: {cheating_counts["repeated_gaze"]}')
+    else:
+        if cheating_flags['repeated_gaze']:
+            cheating_flags['repeated_gaze'] = False
+            start_times['repeated_gaze'] = None
+
+def detect_object_presence(detections, cheating_flags, cheating_counts, cheating_messages, image):
+    current_time = time.time()
+    cheating_objects_detected = [d for d in detections if d['name'] in CHEATING_OBJECTS]
+    if cheating_objects_detected:
+        if not cheating_flags['object']:
+            cheating_flags['object'] = True
+            cheating_counts['object'] += 1
+            objects = [d['name'] for d in cheating_objects_detected]
+            timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(current_time))
+            message = {'type': '부정행위 물체 감지', 'start_time': current_time}
+            cheating_messages.append(message)
+            print(f'[{timestamp}] 유형: 부정행위 물체 감지 ({objects}), 횟수: {cheating_counts["object"]}')
+        # 부정행위 물체에 대한 바운딩 박스 그리기
+        for obj in cheating_objects_detected:
+            x1, y1, x2, y2 = obj['bbox']
+            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 2)
+            image = draw_text_korean(image, obj['name'], (x1, y1 - 10), font_size=20, font_color=(0, 0, 255))
+    else:
+        if cheating_flags['object']:
+            cheating_flags['object'] = False
+
+def detect_face_absence(face_present, start_times, cheating_flags, cheating_counts, face_absence_history, cheating_messages):
+    current_time = time.time()
+    if not face_present:
+        if start_times['face_absence'] is None:
+            start_times['face_absence'] = current_time
+        else:
+            elapsed_time = current_time - start_times['face_absence']
+            if elapsed_time >= FACE_ABSENCE_THRESHOLD and not cheating_flags['face_absence_long']:
+                cheating_flags['face_absence_long'] = True
+                cheating_counts['face_absence_long'] += 1
+                timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(current_time))
+                message = {'type': '장기 화면 이탈', 'start_time': current_time}
+                cheating_messages.append(message)
+                print(f'[{timestamp}] 유형: 장기 화면 이탈, 횟수: {cheating_counts["face_absence_long"]}')
+            elif elapsed_time >= FACE_ABSENCE_DURATION:
+                # 3초 이상 이탈한 경우 기록
+                face_absence_history.append(current_time)
+                # 30초 이내의 기록만 유지
+                face_absence_history[:] = [t for t in face_absence_history if current_time - t <= FACE_ABSENCE_WINDOW]
+                if len(face_absence_history) >= FACE_ABSENCE_COUNT_THRESHOLD and not cheating_flags['face_absence_repeat']:
+                    cheating_flags['face_absence_repeat'] = True
+                    cheating_counts['face_absence_repeat'] += 1
+                    timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(current_time))
+                    message = {'type': '반복 화면 이탈', 'start_time': current_time}
+                    cheating_messages.append(message)
+                    print(f'[{timestamp}] 유형: 반복 화면 이탈, 횟수: {cheating_counts["face_absence_repeat"]}')
+    else:
+        if cheating_flags['face_absence_long'] or cheating_flags['face_absence_repeat']:
+            cheating_flags['face_absence_long'] = False
+            cheating_flags['face_absence_repeat'] = False
+            start_times['face_absence'] = None
+
+
+def detect_hand_gestures(hand_landmarks_list, start_times, cheating_flags, cheating_counts, cheating_messages):
+    current_time = time.time()
+    hand_gesture_detected = False
+
+    for hand_landmarks in hand_landmarks_list:
+        gesture = recognize_hand_gesture(hand_landmarks)
+        if gesture != 'fist' and gesture != 'palm':
+            hand_gesture_detected = True
+            if start_times['hand_gesture'] is None:
+                start_times['hand_gesture'] = current_time
+            else:
+                elapsed_time = current_time - start_times['hand_gesture']
+                if elapsed_time >= HAND_GESTURE_THRESHOLD and not cheating_flags['hand_gesture']:
+                    cheating_flags['hand_gesture'] = True
+                    cheating_counts['hand_gesture'] += 1
+                    timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(current_time))
+                    message = {'type': '특정 손동작 반복', 'start_time': current_time}
+                    cheating_messages.append(message)
+                    print(f'[{timestamp}] 부정행위 감지! 유형: 특정 손동작 반복, 횟수: {cheating_counts["hand_gesture"]}')
+        else:
+            start_times['hand_gesture'] = None
+            cheating_flags['hand_gesture'] = False
+
+    if not hand_gesture_detected:
+        start_times['hand_gesture'] = None
+        cheating_flags['hand_gesture'] = False
+
+def detect_head_turn(pitch, yaw, start_times, cheating_flags, cheating_counts, head_turn_history, cheating_messages):
+    current_time = time.time()
+    if abs(yaw) > HEAD_TURN_THRESHOLD:
+        if start_times['head_turn'] is None:
+            start_times['head_turn'] = current_time
+        else:
+            elapsed_time = current_time - start_times['head_turn']
+            if elapsed_time >= HEAD_TURN_DURATION and not cheating_flags['head_turn_long']:
+                cheating_flags['head_turn_long'] = True
+                cheating_counts['head_turn_long'] += 1
+                timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(current_time))
+                message = {'type': '고개 돌림 유지', 'start_time': current_time}
+                cheating_messages.append(message)
+                print(f'[{timestamp}] 유형: 고개 돌림 유지, 횟수: {cheating_counts["head_turn_long"]}')
+            elif elapsed_time >= HEAD_TURN_REPEAT_DURATION:
+                # 3초 이상 고개를 돌린 경우 기록
+                head_turn_history.append(current_time)
+                # 30초 이내의 기록만 유지
+                head_turn_history[:] = [t for t in head_turn_history if current_time - t <= HEAD_TURN_WINDOW]
+                if len(head_turn_history) >= HEAD_TURN_COUNT_THRESHOLD and not cheating_flags['head_turn_repeat']:
+                    cheating_flags['head_turn_repeat'] = True
+                    cheating_counts['head_turn_repeat'] += 1
+                    timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(current_time))
+                    message = {'type': '고개 돌림 반복', 'start_time': current_time}
+                    cheating_messages.append(message)
+                    print(f'[{timestamp}] 유형: 고개 돌림 반복, 횟수: {cheating_counts["head_turn_repeat"]}')
+    else:
+        if cheating_flags['head_turn_long'] or cheating_flags['head_turn_repeat']:
+            cheating_flags['head_turn_long'] = False
+            cheating_flags['head_turn_repeat'] = False
+            start_times['head_turn'] = None
+
+def detect_eye_movement(eye_center, image_shape, start_times, cheating_flags, cheating_counts, cheating_messages):
+    current_time = time.time()
+
+    # 시선이 중앙에서 얼마나 벗어났는지 계산
+    image_center = (image_shape[1] // 2, image_shape[0] // 2)
+    dx = eye_center[0] - image_center[0]
+
+    # 눈동자가 좌우로 많이 움직였는지 판단
+    if abs(dx) > EYE_MOVEMENT_THRESHOLD:
+        if start_times['eye_movement'] is None:
+            start_times['eye_movement'] = current_time
+        else:
+            elapsed_time = current_time - start_times['eye_movement']
+            if elapsed_time >= 2 and not cheating_flags['eye_movement']:
+                cheating_flags['eye_movement'] = True
+                cheating_counts['eye_movement'] += 1
+                timestamp = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(current_time))
+                message = {'type': '눈동자 움직임', 'start_time': current_time}
+                cheating_messages.append(message)
+                print(f'[{timestamp}] 유형: 눈동자 움직임, 횟수: {cheating_counts["eye_movement"]}')
+    else:
+        if cheating_flags['eye_movement']:
+            cheating_flags['eye_movement'] = False
+            start_times['eye_movement'] = None
\ No newline at end of file
Index: src/ai/4tune_AI/gaze_ver2/main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/ai/4tune_AI/gaze_ver2/main.py b/src/ai/4tune_AI/gaze_ver2/main.py
new file mode 100644
--- /dev/null	(date 1733546536111)
+++ b/src/ai/4tune_AI/gaze_ver2/main.py	(date 1733546536111)
@@ -0,0 +1,181 @@
+# main.py
+
+import warnings
+warnings.filterwarnings("ignore", category=FutureWarning)
+import mediapipe as mp
+import torch
+from fastapi import FastAPI, UploadFile, File, Form
+from pydantic import BaseModel
+from detectors import *
+from starlette.responses import JSONResponse
+
+app = FastAPI()
+
+# 부정행위 감지에 필요한 전역 변수 초기화
+mp_face_mesh = mp.solutions.face_mesh
+mp_face_detection = mp.solutions.face_detection
+mp_hands = mp.solutions.hands
+
+face_mesh = mp_face_mesh.FaceMesh(
+    max_num_faces=1,
+    refine_landmarks=True,
+    min_detection_confidence=0.5,
+    min_tracking_confidence=0.5
+)
+face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)
+hands = mp_hands.Hands(
+    max_num_hands=2,
+    min_detection_confidence=0.5,
+    min_tracking_confidence=0.5
+)
+
+# 객체 탐지 모델 로드 (YOLOv5l)
+model = torch.hub.load('ultralytics/yolov5', 'yolov5l')
+
+# 부정행위 관련 변수 초기화
+start_times = {
+    'look_around': None,
+    'face_absence': None,
+    'head_turn': None,
+    'hand_gesture': None,
+    'eye_movement': None,
+    'repeated_gaze': None
+}
+cheating_flags = {
+    'look_around': False,
+    'repeated_gaze': False,
+    'object': False,
+    'face_absence_long': False,
+    'face_absence_repeat': False,
+    'hand_gesture': False,
+    'head_turn_long': False,
+    'head_turn_repeat': False,
+    'eye_movement': False
+}
+cheating_counts = {
+    'look_around': 0,
+    'repeated_gaze': 0,
+    'object': 0,
+    'face_absence_long': 0,
+    'face_absence_repeat': 0,
+    'hand_gesture': 0,
+    'head_turn_long': 0,
+    'head_turn_repeat': 0,
+    'eye_movement': 0
+}
+
+gaze_history = []
+face_absence_history = []
+head_turn_history = []
+
+# 부정행위 메시지를 저장할 리스트
+cheating_messages = []
+
+class CheatingResult(BaseModel):
+    user_id: str
+    cheating_counts: dict
+    timestamp: str
+
+@app.post("/process_video")
+async def process_video(user_id: str = Form(...), file: UploadFile = File(...)):
+    # 비디오 파일 읽기
+    video_bytes = await file.read()
+    np_arr = np.frombuffer(video_bytes, np.uint8)
+    image = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
+
+    # 이미지 복사 (객체 탐지용)
+    image_for_detection = image.copy()
+
+    # BGR 이미지를 RGB로 변환
+    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
+
+    # 성능 향상을 위해 이미지 쓰기 권한 해제
+    image_rgb.flags.writeable = False
+
+    # 얼굴 검출
+    face_detection_results = face_detection.process(image_rgb)
+    face_present = face_detection_results.detections is not None
+
+    # 얼굴 랜드마크 추출
+    face_mesh_results = face_mesh.process(image_rgb)
+
+    # 손 랜드마크 추출
+    hands_results = hands.process(image_rgb)
+
+    # 객체 탐지
+    object_results = model(image_for_detection)
+
+    # 이미지 쓰기 권한 재설정
+    image_rgb.flags.writeable = True
+
+    # 얼굴 부정행위 감지 (자리 이탈)
+    detect_face_absence(face_present, start_times, cheating_flags, cheating_counts, face_absence_history, cheating_messages)
+
+    if face_mesh_results.multi_face_landmarks:
+        face_landmarks = face_mesh_results.multi_face_landmarks[0]
+        landmarks = get_landmarks(face_landmarks, image.shape)
+
+        # 머리 자세 추정
+        pitch, yaw, roll = calculate_head_pose(landmarks, image.shape)
+
+        # 주변 응시 감지
+        detect_look_around(pitch, yaw, start_times, cheating_flags, cheating_counts, cheating_messages)
+
+        # 고개 돌림 감지
+        detect_head_turn(pitch, yaw, start_times, cheating_flags, cheating_counts, head_turn_history, cheating_messages)
+
+        # 눈동자 움직임 감지
+        eye_center = calculate_eye_position(landmarks)
+        detect_eye_movement(eye_center, image.shape, start_times, cheating_flags, cheating_counts, cheating_messages)
+
+        # 시선 위치 추정
+        gaze_point = get_gaze_position(landmarks)
+
+        # 화면을 격자로 나누어 시선 위치를 감지
+        grid_row = int(gaze_point[1] / (image.shape[0] / GRID_ROWS))
+        grid_col = int(gaze_point[0] / (image.shape[1] / GRID_COLS))
+        grid_position = (grid_row, grid_col)
+
+        # 동일 위치 반복 응시 감지
+        detect_repeated_gaze(grid_position, gaze_history, start_times, cheating_flags, cheating_counts, cheating_messages, pitch)
+
+    else:
+        # 얼굴 랜드마크가 검출되지 않는 경우
+        start_times['look_around'] = None
+        cheating_flags['look_around'] = False
+        start_times['head_turn'] = None
+        cheating_flags['head_turn_long'] = False
+
+    # 손동작 감지
+    if hands_results.multi_hand_landmarks:
+        hand_landmarks_list = hands_results.multi_hand_landmarks
+        detect_hand_gestures(hand_landmarks_list, start_times, cheating_flags, cheating_counts, cheating_messages)
+    else:
+        start_times['hand_gesture'] = None
+        cheating_flags['hand_gesture'] = False
+
+    # 객체 탐지 결과 처리
+    detections = []
+    for *box, conf, cls in object_results.xyxy[0]:
+        if conf >= 0.6:  # 신뢰도 임계값 조정
+            name = object_results.names[int(cls)]
+            x1, y1, x2, y2 = map(int, box)
+            detections.append({'name': name, 'bbox': (x1, y1, x2, y2), 'conf': float(conf)})
+
+    # 부정행위 물체 감지
+    detect_object_presence(detections, cheating_flags, cheating_counts, cheating_messages, image)
+
+    # 현재 시간
+    current_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time()))
+
+    # 결과 반환
+    result = {
+        'user_id': user_id,
+        'cheating_counts': cheating_counts,
+        'timestamp': current_time
+    }
+
+    return JSONResponse(content=result)
+
+# FastAPI 실행 (개발용)
+# uvicorn main:app --host 0.0.0.0 --port 8000
\ No newline at end of file
Index: src/ai/4tune_AI/test_gaze/main.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/ai/4tune_AI/test_gaze/main.py b/src/ai/4tune_AI/test_gaze/main.py
new file mode 100644
--- /dev/null	(date 1733546536113)
+++ b/src/ai/4tune_AI/test_gaze/main.py	(date 1733546536113)
@@ -0,0 +1,165 @@
+import cv2
+import mediapipe as mp
+import time
+
+from utils import draw_text_korean, calculate_head_pose, calculate_eye_direction, detect_hand_gesture
+from constants import CHEATING_THRESHOLD, HEAD_TURN_THRESHOLD, EYE_TURN_THRESHOLD
+from detectors import (
+    detect_face_absence,
+    detect_head_turn,
+    detect_eye_movement,
+    detect_hand_gesture_wrapper
+)
+
+# MediaPipe 초기화
+mp_face_mesh = mp.solutions.face_mesh
+mp_face_detection = mp.solutions.face_detection
+mp_hands = mp.solutions.hands
+
+face_mesh = mp_face_mesh.FaceMesh(
+    max_num_faces=1,
+    refine_landmarks=True,
+    min_detection_confidence=0.5,
+    min_tracking_confidence=0.5
+)
+face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)
+hands = mp_hands.Hands(
+    max_num_hands=2,  # 두 손 인식을 위해 2로 설정
+    min_detection_confidence=0.5,
+    min_tracking_confidence=0.5
+)
+
+# 그리기 유틸리티
+mp_drawing = mp.solutions.drawing_utils
+
+# 부정행위 관련 변수 초기화
+start_times = {'head': None, 'eye': None, 'face': None, 'hand': {}}
+cheating_flags = {'head': False, 'eye': False, 'face': False, 'hand': {}}
+cheating_counts = {'head': 0, 'eye': 0, 'face': 0, 'hand': {}}
+
+# 웹캠 열기
+cap = cv2.VideoCapture(0)
+
+while cap.isOpened():
+    success, image = cap.read()
+    if not success:
+        print("카메라에서 프레임을 읽을 수 없습니다.")
+        break
+
+    # 성능 향상을 위해 이미지 쓰기 권한 해제
+    image.flags.writeable = False
+    # BGR 이미지를 RGB로 변환
+    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
+
+    # 얼굴 검출
+    face_results = face_detection.process(image_rgb)
+    face_present = False if not face_results.detections else True
+
+    # 얼굴 부정행위 감지
+    detect_face_absence(face_present, start_times, cheating_flags, cheating_counts)
+
+    # 얼굴 랜드마크 추출
+    face_mesh_results = face_mesh.process(image_rgb)
+
+    # 손 랜드마크 추출
+    hands_results = hands.process(image_rgb)
+
+    # 이미지 쓰기 권한 재설정
+    image.flags.writeable = True
+    # RGB 이미지를 BGR로 변환
+    image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
+
+    if face_mesh_results.multi_face_landmarks:
+        face_landmarks = face_mesh_results.multi_face_landmarks[0]
+
+        # 머리 자세 추정
+        pitch, yaw, roll = calculate_head_pose(face_landmarks, image.shape)
+
+        # 머리 부정행위 감지
+        detect_head_turn(yaw, start_times, cheating_flags, cheating_counts)
+
+        # 눈동자 움직임 추적
+        eye_angle = calculate_eye_direction(face_landmarks, image.shape)
+
+        # 눈동자 부정행위 감지
+        detect_eye_movement(eye_angle, start_times, cheating_flags, cheating_counts)
+
+        # 얼굴 랜드마크 그리기 (디버깅용)
+        mp_drawing.draw_landmarks(
+            image, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS,
+            landmark_drawing_spec=None,
+            connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1)
+        )
+
+        # 머리 자세 정보 표시
+        text = f'Yaw(좌우): {yaw:.1f}, Pitch(상하): {pitch:.1f}, Roll(기울기): {roll:.1f}'
+        image = draw_text_korean(image, text, (30, 30), font_size=20, font_color=(255, 255, 255))
+
+    else:
+        # 얼굴 랜드마크가 검출되지 않는 경우
+        start_times['head'] = None
+        cheating_flags['head'] = False
+        start_times['eye'] = None
+        cheating_flags['eye'] = False
+
+    # 손동작 감지
+    if hands_results.multi_hand_landmarks:
+        for hand_landmarks, hand_info in zip(hands_results.multi_hand_landmarks, hands_results.multi_handedness):
+            hand_label = hand_info.classification[0].label  # 'Left' 또는 'Right'
+
+            # 부정행위 관련 변수 초기화
+            if hand_label not in start_times['hand']:
+                start_times['hand'][hand_label] = None
+                cheating_flags['hand'][hand_label] = False
+                cheating_counts['hand'][hand_label] = 0
+
+            # 부정행위 제스처 감지
+            hand_gesture_detected = detect_hand_gesture(hand_landmarks)
+
+            # 손동작 부정행위 감지
+            detect_hand_gesture_wrapper(hand_gesture_detected, hand_label, start_times, cheating_flags, cheating_counts)
+
+            # 손 랜드마크 그리기 (디버깅용)
+            mp_drawing.draw_landmarks(
+                image, hand_landmarks, mp_hands.HAND_CONNECTIONS,
+                mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2),
+                mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2)
+            )
+    else:
+        start_times['hand'] = {}
+        cheating_flags['hand'] = {}
+
+    # 부정행위 상태 표시
+    status_text = ''
+    if cheating_flags['face']:
+        status_text += '부정행위 감지: 얼굴 미검출\n'
+    if cheating_flags['head']:
+        status_text += '부정행위 감지: 고개 돌림\n'
+    if cheating_flags['eye']:
+        status_text += '부정행위 감지: 눈동자 돌림\n'
+    for hand_label, flag in cheating_flags['hand'].items():
+        if flag:
+            status_text += f'부정행위 감지: 손동작 (손: {hand_label})\n'
+    if status_text == '':
+        status_text = '정상 상태'
+
+    # 상태 표시
+    y0, dy = 60, 30
+    for i, line in enumerate(status_text.strip().split('\n')):
+        y = y0 + i * dy
+        image = draw_text_korean(
+            image,
+            line,
+            (30, y),
+            font_size=20,
+            font_color=(0, 0, 255) if '부정행위' in line else (0, 255, 0)
+        )
+
+    # 결과 이미지 출력
+    cv2.imshow('Gaze and Motion Tracking', image)
+
+    if cv2.waitKey(5) & 0xFF == 27:  # ESC 키를 누르면 종료
+        break
+
+cap.release()
+cv2.destroyAllWindows()
\ No newline at end of file
Index: src/ai/4tune_AI/test_gaze/testing.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/ai/4tune_AI/test_gaze/testing.py b/src/ai/4tune_AI/test_gaze/testing.py
new file mode 100644
--- /dev/null	(date 1733546536113)
+++ b/src/ai/4tune_AI/test_gaze/testing.py	(date 1733546536113)
@@ -0,0 +1,243 @@
+import cv2
+import mediapipe as mp
+import numpy as np
+from PIL import Image, ImageDraw, ImageFont
+import time
+import math
+
+# MediaPipe 초기화
+mp_face_mesh = mp.solutions.face_mesh
+mp_face_detection = mp.solutions.face_detection
+face_mesh = mp_face_mesh.FaceMesh(
+    max_num_faces=1,
+    refine_landmarks=True,
+    min_detection_confidence=0.5,
+    min_tracking_confidence=0.5)
+face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)
+
+# 그리기 유틸리티
+mp_drawing = mp.solutions.drawing_utils
+
+def draw_text_korean(image, text, position, font_size=30, font_color=(0, 0, 255)):
+    # OpenCV 이미지를 PIL 이미지로 변환
+    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
+    draw = ImageDraw.Draw(image_pil)
+
+    # 폰트 설정 (한글 폰트 경로 지정 필요)
+    font = ImageFont.truetype('/Library/Fonts/AppleGothic.ttf', font_size)  # MacOS의 경우
+    # font = ImageFont.truetype('C:/Windows/Fonts/malgun.ttf', font_size)  # Windows의 경우
+
+    # 텍스트 그리기
+    draw.text(position, text, font=font, fill=font_color)
+
+    # PIL 이미지를 OpenCV 이미지로 변환
+    image = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)
+    return image
+
+def calculate_head_pose(landmarks, image_shape):
+    # 3D 모델 포인트 설정
+    model_points = np.array([
+        (0.0, 0.0, 0.0),             # 코 끝: 1번 랜드마크
+        (0.0, -330.0, -65.0),        # 턱 끝: 152번 랜드마크
+        (-225.0, 170.0, -135.0),     # 왼쪽 눈 좌측 끝: 33번 랜드마크
+        (225.0, 170.0, -135.0),      # 오른쪽 눈 우측 끝: 263번 랜드마크
+        (-150.0, -150.0, -125.0),    # 입 좌측 끝: 78번 랜드마크
+        (150.0, -150.0, -125.0)      # 입 우측 끝: 308번 랜드마크
+    ])
+
+    image_points = np.array([
+        (landmarks.landmark[1].x * image_shape[1], landmarks.landmark[1].y * image_shape[0]),    # 코 끝
+        (landmarks.landmark[152].x * image_shape[1], landmarks.landmark[152].y * image_shape[0]),  # 턱 끝
+        (landmarks.landmark[33].x * image_shape[1], landmarks.landmark[33].y * image_shape[0]),   # 왼쪽 눈 좌측 끝
+        (landmarks.landmark[263].x * image_shape[1], landmarks.landmark[263].y * image_shape[0]),  # 오른쪽 눈 우측 끝
+        (landmarks.landmark[78].x * image_shape[1], landmarks.landmark[78].y * image_shape[0]),   # 입 좌측 끝
+        (landmarks.landmark[308].x * image_shape[1], landmarks.landmark[308].y * image_shape[0])  # 입 우측 끝
+    ], dtype='double')
+
+    # 카메라 매트릭스 설정
+    focal_length = image_shape[1]
+    center = (image_shape[1] / 2, image_shape[0] / 2)
+    camera_matrix = np.array(
+        [[focal_length, 0, center[0]],
+         [0, focal_length, center[1]],
+         [0, 0, 1]], dtype='double')
+
+    dist_coeffs = np.zeros((4, 1))  # 왜곡 계수는 0으로 설정
+
+    # SolvePnP를 사용하여 회전 및 변환 벡터 계산
+    success, rotation_vector, translation_vector = cv2.solvePnP(
+        model_points, image_points, camera_matrix, dist_coeffs)
+
+    # 회전 벡터를 오일러 각도로 변환
+    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
+    pose_matrix = cv2.hconcat((rotation_matrix, translation_vector))
+    _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(pose_matrix)
+
+    pitch, yaw, roll = [angle[0] for angle in euler_angles]
+
+    return pitch, yaw, roll
+
+def calculate_eye_direction(landmarks, image_shape):
+    # 왼쪽 및 오른쪽 눈동자 중심 계산
+    h, w = image_shape[:2]
+
+    left_eye = landmarks.landmark[468]  # 왼쪽 눈동자 중심
+    right_eye = landmarks.landmark[473]  # 오른쪽 눈동자 중심
+
+    left_eye_point = np.array([left_eye.x * w, left_eye.y * h])
+    right_eye_point = np.array([right_eye.x * w, right_eye.y * h])
+
+    # 눈동자 중심의 평균 좌표 계산
+    eyes_center = (left_eye_point + right_eye_point) / 2
+
+    # 코 끝 좌표 추출
+    nose_tip = landmarks.landmark[1]
+    nose_point = np.array([nose_tip.x * w, nose_tip.y * h])
+
+    # 시선 벡터 계산
+    gaze_vector = eyes_center - nose_point
+
+    # 시선 방향 계산 (각도)
+    dx = gaze_vector[0]
+    dy = -gaze_vector[1]  # y축 반전
+
+    angle = math.degrees(math.atan2(dy, dx))
+    if angle < 0:
+        angle += 360
+
+    return angle
+
+# 부정행위 관련 변수 초기화
+start_times = {'head': None, 'eye': None, 'face': None}
+cheating_flags = {'head': False, 'eye': False, 'face': False}
+cheating_counts = {'head': 0, 'eye': 0, 'face': 0}
+
+# 부정행위로 간주할 지속 시간 (초)
+CHEATING_THRESHOLD = 3  # 3초 이상 지속 시 부정행위로 판단
+
+# 웹캠 열기
+cap = cv2.VideoCapture(0)
+
+while cap.isOpened():
+    success, image = cap.read()
+    if not success:
+        print("카메라에서 프레임을 읽을 수 없습니다.")
+        break
+
+    # 성능 향상을 위해 이미지 쓰기 권한 해제
+    image.flags.writeable = False
+    # BGR 이미지를 RGB로 변환
+    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
+
+    # 얼굴 검출
+    face_results = face_detection.process(image_rgb)
+    face_present = False if not face_results.detections else True
+
+    # 얼굴이 검출되지 않는 경우
+    if not face_present:
+        if start_times['face'] is None:
+            start_times['face'] = time.time()
+        else:
+            elapsed_time = time.time() - start_times['face']
+            if elapsed_time >= CHEATING_THRESHOLD and not cheating_flags['face']:
+                cheating_flags['face'] = True
+                cheating_counts['face'] += 1
+                current_time = time.strftime("%Y-%m-%d %H:%M:%S")
+                print(f'부정행위 감지! 유형: 얼굴 미검출, 시간: {current_time}, 횟수: {cheating_counts["face"]}')
+    else:
+        start_times['face'] = None
+        cheating_flags['face'] = False
+
+    # 얼굴 랜드마크 추출
+    face_mesh_results = face_mesh.process(image_rgb)
+
+    # 이미지 쓰기 권한 재설정
+    image.flags.writeable = True
+    # RGB 이미지를 BGR로 변환
+    image = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
+
+    if face_mesh_results.multi_face_landmarks:
+        face_landmarks = face_mesh_results.multi_face_landmarks[0]
+
+        # 머리 자세 추정
+        pitch, yaw, roll = calculate_head_pose(face_landmarks, image.shape)
+
+        # 머리 회전 각도 기준치 설정
+        HEAD_TURN_THRESHOLD = 20  # 각도 절댓값이 20도 이상이면 고개를 돌린 것으로 판단
+
+        if abs(yaw) > HEAD_TURN_THRESHOLD:
+            if start_times['head'] is None:
+                start_times['head'] = time.time()
+            else:
+                elapsed_time = time.time() - start_times['head']
+                if elapsed_time >= CHEATING_THRESHOLD and not cheating_flags['head']:
+                    cheating_flags['head'] = True
+                    cheating_counts['head'] += 1
+                    current_time = time.strftime("%Y-%m-%d %H:%M:%S")
+                    print(f'부정행위 감지! 유형: 고개 돌림, 시간: {current_time}, 횟수: {cheating_counts["head"]}')
+        else:
+            start_times['head'] = None
+            cheating_flags['head'] = False
+
+        # 눈동자 움직임 추적
+        eye_angle = calculate_eye_direction(face_landmarks, image.shape)
+
+        # 눈동자 각도 기준치 설정
+        EYE_TURN_THRESHOLD = 20  # 정면 기준 좌우 20도 이상이면 눈동자를 돌린 것으로 판단
+
+        if eye_angle < (90 - EYE_TURN_THRESHOLD) or eye_angle > (90 + EYE_TURN_THRESHOLD):
+            if start_times['eye'] is None:
+                start_times['eye'] = time.time()
+            else:
+                elapsed_time = time.time() - start_times['eye']
+                if elapsed_time >= CHEATING_THRESHOLD and not cheating_flags['eye']:
+                    cheating_flags['eye'] = True
+                    cheating_counts['eye'] += 1
+                    current_time = time.strftime("%Y-%m-%d %H:%M:%S")
+                    print(f'부정행위 감지! 유형: 눈동자 돌림, 시간: {current_time}, 횟수: {cheating_counts["eye"]}')
+        else:
+            start_times['eye'] = None
+            cheating_flags['eye'] = False
+
+        # 얼굴 랜드마크 그리기 (디버깅용)
+        mp_drawing.draw_landmarks(
+            image, face_landmarks, mp_face_mesh.FACEMESH_CONTOURS,
+            landmark_drawing_spec=None,
+            connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1))
+
+        # 머리 자세 정보 표시
+        text = f'Yaw(좌우): {yaw:.1f}, Pitch(상하): {pitch:.1f}, Roll(기울기): {roll:.1f}'
+        image = draw_text_korean(image, text, (30, 30), font_size=20, font_color=(255, 255, 255))
+
+    else:
+        # 얼굴 랜드마크가 검출되지 않는 경우
+        start_times['head'] = None
+        cheating_flags['head'] = False
+        start_times['eye'] = None
+        cheating_flags['eye'] = False
+
+    # 부정행위 상태 표시
+    status_text = ''
+    if cheating_flags['face']:
+        status_text += '부정행위 감지: 얼굴 미검출\n'
+    if cheating_flags['head']:
+        status_text += '부정행위 감지: 고개 돌림\n'
+    if cheating_flags['eye']:
+        status_text += '부정행위 감지: 눈동자 돌림\n'
+    if status_text == '':
+        status_text = '정상 상태'
+
+    # 상태 표시
+    y0, dy = 60, 30
+    for i, line in enumerate(status_text.split('\n')):
+        y = y0 + i * dy
+        image = draw_text_korean(image, line, (30, y), font_size=20, font_color=(0, 0, 255) if '부정행위' in line else (0, 255, 0))
+
+    # 결과 이미지 출력
+    cv2.imshow('Gaze and Motion Tracking', image)
+
+    if cv2.waitKey(5) & 0xFF == 27:  # ESC 키를 누르면 종료
+        break
+
+cap.release()
+cv2.destroyAllWindows()
\ No newline at end of file
Index: src/ai/4tune_AI/test_gaze/utils.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/ai/4tune_AI/test_gaze/utils.py b/src/ai/4tune_AI/test_gaze/utils.py
new file mode 100644
--- /dev/null	(date 1733546536114)
+++ b/src/ai/4tune_AI/test_gaze/utils.py	(date 1733546536114)
@@ -0,0 +1,116 @@
+import cv2
+import numpy as np
+from PIL import Image, ImageDraw, ImageFont
+import math
+
+def draw_text_korean(image, text, position, font_size=30, font_color=(0, 0, 255)):
+    # OpenCV 이미지를 PIL 이미지로 변환
+    image_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
+    draw = ImageDraw.Draw(image_pil)
+
+    # 폰트 설정 (한글 폰트 경로 지정 필요)
+    font = ImageFont.truetype('/Library/Fonts/AppleGothic.ttf', font_size)  # MacOS의 경우
+    # font = ImageFont.truetype('C:/Windows/Fonts/malgun.ttf', font_size)  # Windows의 경우
+
+    # 텍스트 그리기
+    draw.text(position, text, font=font, fill=font_color)
+
+    # PIL 이미지를 OpenCV 이미지로 변환
+    image = cv2.cvtColor(np.array(image_pil), cv2.COLOR_RGB2BGR)
+    return image
+
+def calculate_head_pose(landmarks, image_shape):
+    # 3D 모델 포인트 설정
+    model_points = np.array([
+        (0.0, 0.0, 0.0),             # 코 끝: 1번 랜드마크
+        (0.0, -330.0, -65.0),        # 턱 끝: 152번 랜드마크
+        (-225.0, 170.0, -135.0),     # 왼쪽 눈 좌측 끝: 33번 랜드마크
+        (225.0, 170.0, -135.0),      # 오른쪽 눈 우측 끝: 263번 랜드마크
+        (-150.0, -150.0, -125.0),    # 입 좌측 끝: 78번 랜드마크
+        (150.0, -150.0, -125.0)      # 입 우측 끝: 308번 랜드마크
+    ])
+
+    image_points = np.array([
+        (landmarks.landmark[1].x * image_shape[1], landmarks.landmark[1].y * image_shape[0]),    # 코 끝
+        (landmarks.landmark[152].x * image_shape[1], landmarks.landmark[152].y * image_shape[0]),  # 턱 끝
+        (landmarks.landmark[33].x * image_shape[1], landmarks.landmark[33].y * image_shape[0]),   # 왼쪽 눈 좌측 끝
+        (landmarks.landmark[263].x * image_shape[1], landmarks.landmark[263].y * image_shape[0]),  # 오른쪽 눈 우측 끝
+        (landmarks.landmark[78].x * image_shape[1], landmarks.landmark[78].y * image_shape[0]),   # 입 좌측 끝
+        (landmarks.landmark[308].x * image_shape[1], landmarks.landmark[308].y * image_shape[0])  # 입 우측 끝
+    ], dtype='double')
+
+    # 카메라 매트릭스 설정
+    focal_length = image_shape[1]
+    center = (image_shape[1] / 2, image_shape[0] / 2)
+    camera_matrix = np.array(
+        [[focal_length, 0, center[0]],
+         [0, focal_length, center[1]],
+         [0, 0, 1]], dtype='double')
+
+    dist_coeffs = np.zeros((4, 1))  # 왜곡 계수는 0으로 설정
+
+    # SolvePnP를 사용하여 회전 및 변환 벡터 계산
+    success, rotation_vector, translation_vector = cv2.solvePnP(
+        model_points, image_points, camera_matrix, dist_coeffs)
+
+    # 회전 벡터를 오일러 각도로 변환
+    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)
+    pose_matrix = cv2.hconcat((rotation_matrix, translation_vector))
+    _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(pose_matrix)
+
+    pitch, yaw, roll = [angle[0] for angle in euler_angles]
+
+    return pitch, yaw, roll
+
+def calculate_eye_direction(landmarks, image_shape):
+    # 왼쪽 및 오른쪽 눈동자 중심 계산
+    h, w = image_shape[:2]
+
+    left_eye = landmarks.landmark[468]  # 왼쪽 눈동자 중심
+    right_eye = landmarks.landmark[473]  # 오른쪽 눈동자 중심
+
+    left_eye_point = np.array([left_eye.x * w, left_eye.y * h])
+    right_eye_point = np.array([right_eye.x * w, right_eye.y * h])
+
+    # 눈동자 중심의 평균 좌표 계산
+    eyes_center = (left_eye_point + right_eye_point) / 2
+
+    # 코 끝 좌표 추출
+    nose_tip = landmarks.landmark[1]
+    nose_point = np.array([nose_tip.x * w, nose_tip.y * h])
+
+    # 시선 벡터 계산
+    gaze_vector = eyes_center - nose_point
+
+    # 시선 방향 계산 (각도)
+    dx = gaze_vector[0]
+    dy = -gaze_vector[1]  # y축 반전
+
+    angle = math.degrees(math.atan2(dy, dx))
+    if angle < 0:
+        angle += 360
+
+    return angle
+
+def detect_hand_gesture(hand_landmarks):
+    # 손가락이 펴져 있는지 확인하여 특정 제스처를 인식
+    # 엄지, 검지, 중지, 약지, 소지에 대한 랜드마크 인덱스
+    finger_tips = [4, 8, 12, 16, 20]
+    finger_pip = [3, 7, 11, 15, 19]
+
+    fingers_status = []
+
+    for tip, pip in zip(finger_tips, finger_pip):
+        tip_y = hand_landmarks.landmark[tip].y
+        pip_y = hand_landmarks.landmark[pip].y
+
+        if tip_y < pip_y:
+            fingers_status.append(1)  # 손가락 펴짐
+        else:
+            fingers_status.append(0)  # 손가락 구부러짐
+
+    # 모든 손가락이 펴져 있으면 특정 제스처로 판단
+    if sum(fingers_status) == 5:
+        return True  # 부정행위 제스처 감지
+    else:
+        return False
\ No newline at end of file
Index: src/ai/4tune_AI/test_gaze/detectors.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/ai/4tune_AI/test_gaze/detectors.py b/src/ai/4tune_AI/test_gaze/detectors.py
new file mode 100644
--- /dev/null	(date 1733546536112)
+++ b/src/ai/4tune_AI/test_gaze/detectors.py	(date 1733546536112)
@@ -0,0 +1,62 @@
+import time
+from constants import CHEATING_THRESHOLD, HEAD_TURN_THRESHOLD, EYE_TURN_THRESHOLD
+
+def detect_face_absence(face_present, start_times, cheating_flags, cheating_counts):
+    if not face_present:
+        if start_times['face'] is None:
+            start_times['face'] = time.time()
+        else:
+            elapsed_time = time.time() - start_times['face']
+            if elapsed_time >= CHEATING_THRESHOLD and not cheating_flags['face']:
+                cheating_flags['face'] = True
+                cheating_counts['face'] += 1
+                current_time = time.strftime("%Y-%m-%d %H:%M:%S")
+                print(f'부정행위 감지! 유형: 얼굴 미검출, 시간: {current_time}, 횟수: {cheating_counts["face"]}')
+    else:
+        start_times['face'] = None
+        cheating_flags['face'] = False
+
+def detect_head_turn(yaw, start_times, cheating_flags, cheating_counts):
+    if abs(yaw) > HEAD_TURN_THRESHOLD:
+        if start_times['head'] is None:
+            start_times['head'] = time.time()
+        else:
+            elapsed_time = time.time() - start_times['head']
+            if elapsed_time >= CHEATING_THRESHOLD and not cheating_flags['head']:
+                cheating_flags['head'] = True
+                cheating_counts['head'] += 1
+                current_time = time.strftime("%Y-%m-%d %H:%M:%S")
+                print(f'부정행위 감지! 유형: 고개 돌림, 시간: {current_time}, 횟수: {cheating_counts["head"]}')
+    else:
+        start_times['head'] = None
+        cheating_flags['head'] = False
+
+def detect_eye_movement(eye_angle, start_times, cheating_flags, cheating_counts):
+    if eye_angle < (90 - EYE_TURN_THRESHOLD) or eye_angle > (90 + EYE_TURN_THRESHOLD):
+        if start_times['eye'] is None:
+            start_times['eye'] = time.time()
+        else:
+            elapsed_time = time.time() - start_times['eye']
+            if elapsed_time >= CHEATING_THRESHOLD and not cheating_flags['eye']:
+                cheating_flags['eye'] = True
+                cheating_counts['eye'] += 1
+                current_time = time.strftime("%Y-%m-%d %H:%M:%S")
+                print(f'부정행위 감지! 유형: 눈동자 돌림, 시간: {current_time}, 횟수: {cheating_counts["eye"]}')
+    else:
+        start_times['eye'] = None
+        cheating_flags['eye'] = False
+
+def detect_hand_gesture_wrapper(hand_gesture_detected, hand_label, start_times, cheating_flags, cheating_counts):
+    if hand_gesture_detected:
+        if start_times['hand'].get(hand_label) is None:
+            start_times['hand'][hand_label] = time.time()
+        else:
+            elapsed_time = time.time() - start_times['hand'][hand_label]
+            if elapsed_time >= CHEATING_THRESHOLD and not cheating_flags['hand'].get(hand_label, False):
+                cheating_flags['hand'][hand_label] = True
+                cheating_counts['hand'][hand_label] = cheating_counts['hand'].get(hand_label, 0) + 1
+                current_time = time.strftime("%Y-%m-%d %H:%M:%S")
+                print(f'부정행위 감지! 유형: 손동작, 손: {hand_label}, 시간: {current_time}, 횟수: {cheating_counts["hand"][hand_label]}')
+    else:
+        start_times['hand'][hand_label] = None
+        cheating_flags['hand'][hand_label] = False
\ No newline at end of file
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"9fb130f4-ff3a-4d08-b9af-31d0460f5b1f\" name=\"변경\" comment=\"\">\n      <change afterPath=\"$PROJECT_DIR$/.idea/2024-2-SCS4031-4tune-1.iml\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/inspectionProfiles/Project_Default.xml\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/inspectionProfiles/profiles_settings.xml\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/misc.xml\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/sonarlint/issuestore/8/e/8ec9a00bfd09b3190ac6b22251dbb1aa95a0579d\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/sonarlint/issuestore/index.pb\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/sonarlint/securityhotspotstore/8/e/8ec9a00bfd09b3190ac6b22251dbb1aa95a0579d\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/sonarlint/securityhotspotstore/index.pb\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/vcs.xml\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/workspace.xml\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"Git.Settings\">\n    <option name=\"RECENT_BRANCH_BY_REPOSITORY\">\n      <map>\n        <entry key=\"$PROJECT_DIR$\" value=\"main\" />\n      </map>\n    </option>\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n  </component>\n  <component name=\"MarkdownSettingsMigration\">\n    <option name=\"stateVersion\" value=\"1\" />\n  </component>\n  <component name=\"ProjectColorInfo\">{\n  &quot;associatedIndex&quot;: 4\n}</component>\n  <component name=\"ProjectId\" id=\"2o641f8TQ1Srqz0IeYtTkBZ8Eba\" />\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\"><![CDATA[{\n  \"keyToString\": {\n    \"RunOnceActivity.OpenProjectViewOnStart\": \"true\",\n    \"RunOnceActivity.ShowReadmeOnStart\": \"true\",\n    \"WebServerToolWindowFactoryState\": \"false\",\n    \"git-widget-placeholder\": \"ai/feature/initial-setup\",\n    \"last_opened_file_path\": \"/Users/chun/Desktop/2024-2-SCS4031-4tune-1/src/ai/4tune_AI\",\n    \"node.js.detected.package.eslint\": \"true\",\n    \"node.js.detected.package.tslint\": \"true\",\n    \"node.js.selected.package.eslint\": \"(autodetect)\",\n    \"node.js.selected.package.tslint\": \"(autodetect)\",\n    \"vue.rearranger.settings.migration\": \"true\"\n  }\n}]]></component>\n  <component name=\"RecentsManager\">\n    <key name=\"CopyFile.RECENT_KEYS\">\n      <recent name=\"$PROJECT_DIR$/src/ai/4tune_AI\" />\n      <recent name=\"$PROJECT_DIR$/src/ai\" />\n    </key>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"애플리케이션 수준\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"디폴트 작업\">\n      <changelist id=\"9fb130f4-ff3a-4d08-b9af-31d0460f5b1f\" name=\"변경\" comment=\"\" />\n      <created>1730176478192</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1730176478192</updated>\n      <workItem from=\"1730176479713\" duration=\"1676000\" />\n      <workItem from=\"1730375878008\" duration=\"124000\" />\n    </task>\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision dc877692707894d8716e12b97fb670c3988bdcb7)
+++ b/.idea/workspace.xml	(date 1733546856446)
@@ -5,16 +5,23 @@
   </component>
   <component name="ChangeListManager">
     <list default="true" id="9fb130f4-ff3a-4d08-b9af-31d0460f5b1f" name="변경" comment="">
-      <change afterPath="$PROJECT_DIR$/.idea/2024-2-SCS4031-4tune-1.iml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/inspectionProfiles/Project_Default.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/inspectionProfiles/profiles_settings.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/misc.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/sonarlint/issuestore/8/e/8ec9a00bfd09b3190ac6b22251dbb1aa95a0579d" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/sonarlint/issuestore/index.pb" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/sonarlint/securityhotspotstore/8/e/8ec9a00bfd09b3190ac6b22251dbb1aa95a0579d" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/sonarlint/securityhotspotstore/index.pb" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/vcs.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/sonarlint/issuestore/6/c/6cab8a4365ae784aa4f202efee07f97f341353c5" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/sonarlint/issuestore/9/1/910cd19debf0f1bc66164aaa9e87c0ebd1344080" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/sonarlint/issuestore/a/7/a70493e17a32b9711265c1284ac59eb6e5671d82" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/sonarlint/issuestore/b/f/bf708a643db2ad11ba0f446c8def2b82584dd087" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/sonarlint/securityhotspotstore/6/c/6cab8a4365ae784aa4f202efee07f97f341353c5" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/sonarlint/securityhotspotstore/9/1/910cd19debf0f1bc66164aaa9e87c0ebd1344080" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/sonarlint/securityhotspotstore/a/7/a70493e17a32b9711265c1284ac59eb6e5671d82" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/.idea/sonarlint/securityhotspotstore/b/f/bf708a643db2ad11ba0f446c8def2b82584dd087" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/misc.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/misc.xml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/sonarlint/issuestore/index.pb" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/sonarlint/issuestore/index.pb" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/sonarlint/securityhotspotstore/index.pb" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/sonarlint/securityhotspotstore/index.pb" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/ai/4tune_AI/gaze_ver2/constants.py" beforeDir="false" afterPath="$PROJECT_DIR$/src/ai/4tune_AI/gaze_ver2/constants.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/ai/4tune_AI/gaze_ver2/custom_utils.py" beforeDir="false" afterPath="$PROJECT_DIR$/src/ai/4tune_AI/gaze_ver2/custom_utils.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/ai/4tune_AI/gaze_ver2/detectors.py" beforeDir="false" afterPath="$PROJECT_DIR$/src/ai/4tune_AI/gaze_ver2/detectors.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/ai/4tune_AI/gaze_ver2/main.py" beforeDir="false" afterPath="$PROJECT_DIR$/src/ai/4tune_AI/gaze_ver2/main.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/ai/4tune_AI/gaze_ver2/yolov5s.pt" beforeDir="false" />
     </list>
     <option name="SHOW_DIALOG" value="false" />
     <option name="HIGHLIGHT_CONFLICTS" value="true" />
@@ -24,7 +31,7 @@
   <component name="Git.Settings">
     <option name="RECENT_BRANCH_BY_REPOSITORY">
       <map>
-        <entry key="$PROJECT_DIR$" value="main" />
+        <entry key="$PROJECT_DIR$" value="ai/detect" />
       </map>
     </option>
     <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
@@ -46,16 +53,18 @@
     "RunOnceActivity.ShowReadmeOnStart": "true",
     "WebServerToolWindowFactoryState": "false",
     "git-widget-placeholder": "ai/feature/initial-setup",
-    "last_opened_file_path": "/Users/chun/Desktop/2024-2-SCS4031-4tune-1/src/ai/4tune_AI",
+    "last_opened_file_path": "/Users/chun/Desktop/2024-2-SCS4031-4tune-1/src/ai/4tune_AI/gaze_ver2",
     "node.js.detected.package.eslint": "true",
     "node.js.detected.package.tslint": "true",
     "node.js.selected.package.eslint": "(autodetect)",
     "node.js.selected.package.tslint": "(autodetect)",
+    "ts.external.directory.path": "/Applications/PyCharm.app/Contents/plugins/javascript-impl/jsLanguageServicesImpl/external",
     "vue.rearranger.settings.migration": "true"
   }
 }]]></component>
   <component name="RecentsManager">
     <key name="CopyFile.RECENT_KEYS">
+      <recent name="$PROJECT_DIR$/src/ai/4tune_AI/gaze_ver2" />
       <recent name="$PROJECT_DIR$/src/ai/4tune_AI" />
       <recent name="$PROJECT_DIR$/src/ai" />
     </key>
@@ -69,11 +78,22 @@
       <option name="presentableId" value="Default" />
       <updated>1730176478192</updated>
       <workItem from="1730176479713" duration="1676000" />
-      <workItem from="1730375878008" duration="124000" />
+      <workItem from="1730375878008" duration="899000" />
+      <workItem from="1730629095871" duration="599000" />
+      <workItem from="1730702578423" duration="599000" />
+      <workItem from="1730706956076" duration="599000" />
+      <workItem from="1730720619064" duration="1626000" />
+      <workItem from="1731154427257" duration="600000" />
+      <workItem from="1731384196719" duration="1206000" />
+      <workItem from="1731564970150" duration="258000" />
     </task>
     <servers />
   </component>
   <component name="TypeScriptGeneratedFilesManager">
     <option name="version" value="3" />
   </component>
+  <component name="com.intellij.coverage.CoverageDataManagerImpl">
+    <SUITE FILE_PATH="coverage/2024_2_SCS4031_4tune_1$main.coverage" NAME="main 커버리지 결과" MODIFIED="1731994680825" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/src/ai/4tune_AI/gaze_ver2" />
+    <SUITE FILE_PATH="coverage/2024_2_SCS4031_4tune_1$te.coverage" NAME="te 커버리지 결과" MODIFIED="1732438646027" SOURCE_PROVIDER="com.intellij.coverage.DefaultCoverageFileProvider" RUNNER="coverage.py" COVERAGE_BY_TEST_ENABLED="true" COVERAGE_TRACING_ENABLED="false" WORKING_DIRECTORY="$PROJECT_DIR$/src/ai/4tune_AI/test_gaze" />
+  </component>
 </project>
\ No newline at end of file
Index: .idea/misc.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"Black\">\n    <option name=\"sdkName\" value=\"Python 3.7 (Optimal_Classification_Trees)\" />\n  </component>\n  <component name=\"ProjectRootManager\" version=\"2\" project-jdk-name=\"Python 3.7 (Optimal_Classification_Trees)\" project-jdk-type=\"Python SDK\" />\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/misc.xml b/.idea/misc.xml
--- a/.idea/misc.xml	(revision dc877692707894d8716e12b97fb670c3988bdcb7)
+++ b/.idea/misc.xml	(date 1733546536102)
@@ -3,5 +3,5 @@
   <component name="Black">
     <option name="sdkName" value="Python 3.7 (Optimal_Classification_Trees)" />
   </component>
-  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.7 (Optimal_Classification_Trees)" project-jdk-type="Python SDK" />
+  <component name="ProjectRootManager" version="2" project-jdk-name="Python 3.10" project-jdk-type="Python SDK" />
 </project>
\ No newline at end of file
diff --git a/.idea/sonarlint/issuestore/b/f/bf708a643db2ad11ba0f446c8def2b82584dd087 b/.idea/sonarlint/issuestore/b/f/bf708a643db2ad11ba0f446c8def2b82584dd087
new file mode 100644
diff --git a/.idea/sonarlint/securityhotspotstore/b/f/bf708a643db2ad11ba0f446c8def2b82584dd087 b/.idea/sonarlint/securityhotspotstore/b/f/bf708a643db2ad11ba0f446c8def2b82584dd087
new file mode 100644
diff --git a/.idea/sonarlint/securityhotspotstore/a/7/a70493e17a32b9711265c1284ac59eb6e5671d82 b/.idea/sonarlint/securityhotspotstore/a/7/a70493e17a32b9711265c1284ac59eb6e5671d82
new file mode 100644
diff --git a/.idea/sonarlint/securityhotspotstore/6/c/6cab8a4365ae784aa4f202efee07f97f341353c5 b/.idea/sonarlint/securityhotspotstore/6/c/6cab8a4365ae784aa4f202efee07f97f341353c5
new file mode 100644
diff --git a/.idea/sonarlint/securityhotspotstore/9/1/910cd19debf0f1bc66164aaa9e87c0ebd1344080 b/.idea/sonarlint/securityhotspotstore/9/1/910cd19debf0f1bc66164aaa9e87c0ebd1344080
new file mode 100644
